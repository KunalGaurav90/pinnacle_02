{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalGaurav90/pinnacle_02/blob/main/Untitled32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Final, Robust 3D Resume Parser for Google Colab\n",
        "\n",
        "This definitive version uses intelligent parsing, summarization, and data\n",
        "cleaning, with robust name detection to provide a highly accurate and\n",
        "cleanly formatted output in the 3D card.\n",
        "\"\"\"\n",
        "# Step 1: Install required libraries silently\n",
        "!pip install PyPDF2 python-docx spacy -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "\n",
        "# Step 2: Import all necessary modules\n",
        "import os\n",
        "import re\n",
        "import docx\n",
        "import PyPDF2\n",
        "import spacy\n",
        "from IPython.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Load the spaCy model for NLP tasks\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"spaCy model not found. Re-run the cell or check installation.\")\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "# Step 3: Define text extraction and cleaning functions\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Removes extra whitespace and cleans up text for display.\"\"\"\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# Step 4: Define advanced parsing and formatting functions\n",
        "\n",
        "# --- NEW: ROBUST NAME PARSING LOGIC ---\n",
        "def get_name_from_email(email):\n",
        "    \"\"\"Helper function to derive a name from an email address.\"\"\"\n",
        "    if not email or email == \"Not Found\" or \"@\" not in email:\n",
        "        return None\n",
        "    try:\n",
        "        local_part = email.split('@')[0]\n",
        "        local_part = re.sub(r'[._-]', ' ', local_part)\n",
        "        local_part = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', local_part)\n",
        "        name_candidate = local_part.title()\n",
        "        if 1 < len(name_candidate.split()) < 4:\n",
        "            return name_candidate\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def parse_name_final(doc, email, all_headings):\n",
        "    \"\"\"\n",
        "    A robust, multi-step function to find the name.\n",
        "    1. Tries to find a PERSON entity, filtering out common non-name words.\n",
        "    2. Falls back to capitalized words at the start of the document.\n",
        "    3. As a last resort, infers the name from the email address.\n",
        "    \"\"\"\n",
        "    non_name_keywords = ['cloud', 'university', 'technologies', 'solutions', 'inc', 'llc', 'resume', 'cv']\n",
        "\n",
        "    # 1. Try spaCy's PERSON entity recognition\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\" and len(ent.text.split()) < 4:\n",
        "            if not any(keyword in ent.text.lower() for keyword in non_name_keywords):\n",
        "                return ent.text.strip()\n",
        "\n",
        "    # 2. Fallback to the first few lines of text\n",
        "    for line in doc.text.split('\\n')[:5]:\n",
        "        line = line.strip()\n",
        "        if (1 < len(line.split()) < 4 and\n",
        "            all(word.istitle() for word in line.split()) and\n",
        "            line.lower() not in all_headings):\n",
        "            if not any(keyword in line.lower() for keyword in non_name_keywords):\n",
        "                return line\n",
        "\n",
        "    # 3. Final fallback: derive name from email address\n",
        "    name_from_email = get_name_from_email(email)\n",
        "    if name_from_email:\n",
        "        return name_from_email\n",
        "\n",
        "    return \"Not Found\"\n",
        "\n",
        "\n",
        "def parse_contact_smart(text):\n",
        "    email = re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
        "    phone = re.search(r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', text)\n",
        "    return {\n",
        "        \"email\": email.group(0) if email else \"Not Found\",\n",
        "        \"phone\": phone.group(0).strip() if phone else \"Not Found\"\n",
        "    }\n",
        "\n",
        "\n",
        "def parse_section_smart(text, start_keywords, end_keywords):\n",
        "    \"\"\"Extracts content between a start keyword and the next section's keyword.\"\"\"\n",
        "    try:\n",
        "        start_regex = r'\\b(' + '|'.join(start_keywords) + r')\\b'\n",
        "        match = re.search(start_regex, text, re.IGNORECASE)\n",
        "        if not match:\n",
        "            return \"Not Found\"\n",
        "        start_index = match.end()\n",
        "        end_index = len(text)\n",
        "        for end_keyword in end_keywords:\n",
        "            next_match = re.search(r'\\b' + end_keyword + r'\\b', text[start_index:], re.IGNORECASE)\n",
        "            if next_match and (next_match.start() + start_index) < end_index:\n",
        "                end_index = next_match.start() + start_index\n",
        "        section_text = text[start_index:end_index]\n",
        "        return section_text.strip()\n",
        "    except Exception:\n",
        "        return \"Not Found\"\n",
        "\n",
        "\n",
        "def summarize_experience(text, num_sentences=2):\n",
        "    \"\"\"Summarizes the experience section into key bullet points.\"\"\"\n",
        "    if not text or text == \"Not Found\":\n",
        "        return \"Not Found\"\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 20]\n",
        "    summary_points = sentences[:num_sentences]\n",
        "    return \"<br>\".join([f\"• {clean_text(point)}\" for point in summary_points])\n",
        "\n",
        "\n",
        "def parse_skills_cleanly(text):\n",
        "    \"\"\"Identifies and extracts a clean, comma-separated list of skills.\"\"\"\n",
        "    if not text or text == \"Not Found\":\n",
        "        return \"Not Found\"\n",
        "    known_skills = [\n",
        "        'Python', 'Java', 'C++', 'C#', 'JavaScript', 'SQL', 'Tableau', 'Power BI',\n",
        "        'Machine Learning', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'NLP', 'Informatica',\n",
        "        'Data Wrangling', 'Business Analysis', 'Predictive Modelling', 'AWS', 'Azure',\n",
        "        'Docker', 'Git', 'React', 'Angular', 'Vue', 'Node.js', 'Excel', 'Einstein Analytics'\n",
        "    ]\n",
        "    found_skills = set()\n",
        "    for skill in known_skills:\n",
        "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text, re.IGNORECASE):\n",
        "            found_skills.add(skill)\n",
        "    # Split by common separators like comma, semicolon, newline\n",
        "    potential_skills = re.split(r'[,;\\n]', text, re.IGNORECASE)\n",
        "    for p_skill in potential_skills:\n",
        "        p_skill = p_skill.strip()\n",
        "        if p_skill and len(p_skill.split()) < 5: # Basic filtering for short phrases\n",
        "             found_skills.add(p_skill.title()) # Add to set, title case for consistency\n",
        "\n",
        "    return \", \".join(sorted(list(found_skills))) # Return as a sorted comma-separated string\n",
        "\n",
        "# --- NEW: Project and Certification Parsing (simplified) ---\n",
        "def parse_list_section(text):\n",
        "    \"\"\"Parses sections that are likely bulleted lists (Projects, Certifications).\"\"\"\n",
        "    if not text or text == \"Not Found\":\n",
        "        return \"Not Found\"\n",
        "    # Split by common list item indicators (bullets, numbers, newlines followed by caps)\n",
        "    items = re.split(r'[\\n\\*\\-\\d\\.]+\\s*', text)\n",
        "    cleaned_items = [clean_text(item).strip() for item in items if clean_text(item).strip()]\n",
        "    return \"<br>\".join([f\"• {item}\" for item in cleaned_items if len(item) > 10]) # Filter out short items\n",
        "\n",
        "# Step 5: Orchestrate parsing and structure output\n",
        "def parse_resume(file_path):\n",
        "    \"\"\"\n",
        "    Parses a resume file (PDF or DOCX) and extracts key information.\n",
        "    Uses robust methods for name, contact, and section parsing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if file_path.lower().endswith('.pdf'):\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "        elif file_path.lower().endswith('.docx'):\n",
        "            text = extract_text_from_docx(file_path)\n",
        "        else:\n",
        "            return {\"Error\": \"Unsupported file type. Please upload PDF or DOCX.\"}\n",
        "\n",
        "        if not text:\n",
        "            return {\"Error\": \"Could not extract text from the document.\"}\n",
        "\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Define potential section headings to aid parsing\n",
        "        all_headings = [\n",
        "            'education', 'experience', 'work experience', 'skills', 'technical skills',\n",
        "            'projects', 'certifications', 'awards', 'summary', 'about', 'contact'\n",
        "        ]\n",
        "\n",
        "        contact_info = parse_contact_smart(text)\n",
        "        email = contact_info.get(\"email\", \"Not Found\")\n",
        "\n",
        "        # Pass the spaCy doc and all_headings for better context in name parsing\n",
        "        name = parse_name_final(doc, email, all_headings)\n",
        "\n",
        "        # Use defined headings to parse sections\n",
        "        education = parse_section_smart(text, ['Education'], ['Experience', 'Skills', 'Projects', 'Certifications', 'Awards', 'Summary', 'About'])\n",
        "        experience_raw = parse_section_smart(text, ['Experience', 'Work Experience'], ['Education', 'Skills', 'Projects', 'Certifications', 'Awards', 'Summary', 'About'])\n",
        "        experience_summary = summarize_experience(experience_raw) # Summarize experience\n",
        "        skills = parse_section_smart(text, ['Skills', 'Technical Skills'], ['Education', 'Experience', 'Projects', 'Certifications', 'Awards', 'Summary', 'About'])\n",
        "        skills_cleaned = parse_skills_cleanly(skills) # Clean and format skills\n",
        "        projects_raw = parse_section_smart(text, ['Projects'], ['Education', 'Experience', 'Skills', 'Certifications', 'Awards', 'Summary', 'About'])\n",
        "        projects_cleaned = parse_list_section(projects_raw) # Clean and format projects\n",
        "        certifications_raw = parse_section_smart(text, ['Certifications', 'Awards'], ['Education', 'Experience', 'Skills', 'Projects', 'Summary', 'About'])\n",
        "        certifications_cleaned = parse_list_section(certifications_raw) # Clean and format certifications\n",
        "\n",
        "\n",
        "        parsed_data = {\n",
        "            \"Name\": name,\n",
        "            \"Email\": email,\n",
        "            \"Phone\": contact_info.get(\"phone\", \"Not Found\"),\n",
        "            \"Education\": clean_text(education) if education != \"Not Found\" else \"Not Found\",\n",
        "            \"Experience\": experience_summary, # Use summarized experience\n",
        "            \"Skills\": skills_cleaned, # Use cleaned skills\n",
        "            \"Projects\": projects_cleaned, # Use cleaned projects\n",
        "            \"Certifications\": certifications_cleaned # Use cleaned certifications\n",
        "        }\n",
        "\n",
        "        return parsed_data\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"Error\": f\"An error occurred during parsing: {e}\"}\n",
        "\n",
        "\n",
        "# Step 6: Generate 3D Card HTML\n",
        "def create_3d_card(data):\n",
        "    \"\"\"Generates HTML for a 3D flip card based on parsed resume data.\"\"\"\n",
        "    if \"Error\" in data:\n",
        "        return f\"<div style='color: red; font-weight: bold;'>{data['Error']}</div>\"\n",
        "\n",
        "    # Basic styling for the card\n",
        "    css = \"\"\"\n",
        "    .card-container {\n",
        "        width: 300px;\n",
        "        height: 450px;\n",
        "        perspective: 1000px;\n",
        "        margin: 20px auto;\n",
        "    }\n",
        "\n",
        "    .card {\n",
        "        width: 100%;\n",
        "        height: 100%;\n",
        "        position: relative;\n",
        "        transform-style: preserve-3d;\n",
        "        transition: transform 0.8s cubic-bezier(0.175, 0.885, 0.32, 1.275);\n",
        "    }\n",
        "\n",
        "    .card:hover {\n",
        "        transform: rotateY(180deg);\n",
        "    }\n",
        "\n",
        "    .card-face {\n",
        "        position: absolute;\n",
        "        width: 100%;\n",
        "        height: 100%;\n",
        "        backface-visibility: hidden;\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "        padding: 20px;\n",
        "        box-sizing: border-box;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: space-around;\n",
        "        align-items: center;\n",
        "        text-align: center;\n",
        "    }\n",
        "\n",
        "    .card-front {\n",
        "        background-color: #f0f0f0;\n",
        "        color: #333;\n",
        "    }\n",
        "\n",
        "    .card-back {\n",
        "        background-color: #333;\n",
        "        color: #f0f0f0;\n",
        "        transform: rotateY(180deg);\n",
        "        overflow-y: auto; /* Add scroll for long content */\n",
        "        text-align: left;\n",
        "        padding: 20px;\n",
        "    }\n",
        "\n",
        "    .card-back::-webkit-scrollbar {\n",
        "        width: 8px;\n",
        "    }\n",
        "\n",
        "    .card-back::-webkit-scrollbar-track {\n",
        "        background: #555;\n",
        "        border-radius: 10px;\n",
        "    }\n",
        "\n",
        "    .card-back::-webkit-scrollbar-thumb {\n",
        "        background: #888;\n",
        "        border-radius: 10px;\n",
        "    }\n",
        "\n",
        "    .card-back::-webkit-scrollbar-thumb:hover {\n",
        "        background: #bbb;\n",
        "    }\n",
        "\n",
        "\n",
        "    .card-title {\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 10px;\n",
        "    }\n",
        "\n",
        "     .card-section-title {\n",
        "        font-size: 16px;\n",
        "        font-weight: bold;\n",
        "        margin-top: 10px;\n",
        "        margin-bottom: 5px;\n",
        "        border-bottom: 1px solid #f0f0f0;\n",
        "        padding-bottom: 2px;\n",
        "    }\n",
        "\n",
        "    .card-text {\n",
        "        font-size: 14px;\n",
        "        margin-bottom: 5px;\n",
        "    }\n",
        "     .card-list-item {\n",
        "         font-size: 14px;\n",
        "         margin-bottom: 5px;\n",
        "         list-style-type: disc;\n",
        "         margin-left: 20px;\n",
        "         text-align: left;\n",
        "     }\n",
        "    \"\"\"\n",
        "\n",
        "    # Format data for the back of the card\n",
        "    back_content = f\"\"\"\n",
        "    <div class=\"card-section-title\">Contact</div>\n",
        "    <div class=\"card-text\">Email: {data.get('Email', 'Not Found')}</div>\n",
        "    <div class=\"card-text\">Phone: {data.get('Phone', 'Not Found')}</div>\n",
        "\n",
        "    <div class=\"card-section-title\">Education</div>\n",
        "    <div class=\"card-text\">{data.get('Education', 'Not Found')}</div>\n",
        "\n",
        "    <div class=\"card-section-title\">Experience Summary</div>\n",
        "    <div class=\"card-text\">{data.get('Experience', 'Not Found')}</div>\n",
        "\n",
        "    <div class=\"card-section-title\">Skills</div>\n",
        "    <div class=\"card-text\">{data.get('Skills', 'Not Found')}</div>\n",
        "\n",
        "    <div class=\"card-section-title\">Projects</div>\n",
        "    <div class=\"card-text\">{data.get('Projects', 'Not Found')}</div>\n",
        "\n",
        "    <div class=\"card-section-title\">Certifications</div>\n",
        "    <div class=\"card-text\">{data.get('Certifications', 'Not Found')}</div>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <style>{css}</style>\n",
        "    <div class=\"card-container\">\n",
        "        <div class=\"card\">\n",
        "            <div class=\"card-face card-front\">\n",
        "                <div class=\"card-title\">{data.get('Name', 'Not Found')}</div>\n",
        "                 <!-- You can add an image or a brief summary on the front -->\n",
        "                 <img src=\"https://via.placeholder.com/150\" alt=\"Profile Image\" style=\"border-radius: 50%; margin-bottom: 10px;\">\n",
        "                <div class=\"card-text\">Hover to see details</div>\n",
        "            </div>\n",
        "            <div class=\"card-face card-back\">\n",
        "                {back_content}\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "# Step 7: Main Execution Block\n",
        "def main():\n",
        "    \"\"\"Main function to handle file upload, parsing, and display.\"\"\"\n",
        "    print(\"Please upload your resume (PDF or DOCX).\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for file_name in uploaded.keys():\n",
        "        print(f'Uploaded file: {file_name}')\n",
        "        parsed_extended_data = parse_resume(file_name)\n",
        "        if \"Error\" in parsed_extended_data:\n",
        "            print(parsed_extended_data[\"Error\"])\n",
        "        else:\n",
        "            print(\"\\n--- Parsed Resume Data ---\")\n",
        "            for key, value in parsed_extended_data.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "\n",
        "            # Create and display the 3D card\n",
        "            card_html = create_3d_card(parsed_extended_data)\n",
        "            display(HTML(card_html))\n",
        "\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "bj7KpMXjQns6",
        "outputId": "5508d4fa-65c8-4881-bac7-1836f67d45a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/12.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/12.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/12.8 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Please upload your resume (PDF or DOCX).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb211cb8-9a6c-4f55-837c-3663ba280b0d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb211cb8-9a6c-4f55-837c-3663ba280b0d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fank_resume.pdf to fank_resume (2).pdf\n",
            "Uploaded file: fank_resume (2).pdf\n",
            "\n",
            "--- Parsed Resume Data ---\n",
            "Name: Missy Frank\n",
            "Email: MissyFrank@email.com\n",
            "Phone: (703) 555-3334\n",
            "Education: Not Found\n",
            "Experience: • by training model to predict duplicate questions with 72% accuracy using natural language processing (NLP), advanced feature engineering.<br>• and sklearn machine learning (ML) pipelines.\n",
            "Skills: Data Wrangling, Einstein, Informatica, Machine Learning, Predictive Modelling, Python, SQL, Sql Tableau, Tableau\n",
            "Projects: • \" Used SQL and SOQL to cxtract, analysc, and interpret<br>• M data points: defincd<br>• key metrics and visualised data using Excel and Tableau dashboards<br>• \"Enhanced demand forecasting and streamlined data flow for<br>• + interfaces using<br>• Informatica Cloud, cleaning and correlating<br>• K+ customer data records with $<br>• in sales using python and sales analytics<br>• \" Created predictive models to prioritise campaigns and project customer lifetime<br>• value in collaboration with senior management\n",
            "Certifications: Not Found\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    .card-container {\n",
              "        width: 300px;\n",
              "        height: 450px;\n",
              "        perspective: 1000px;\n",
              "        margin: 20px auto;\n",
              "    }\n",
              "\n",
              "    .card {\n",
              "        width: 100%;\n",
              "        height: 100%;\n",
              "        position: relative;\n",
              "        transform-style: preserve-3d;\n",
              "        transition: transform 0.8s cubic-bezier(0.175, 0.885, 0.32, 1.275);\n",
              "    }\n",
              "\n",
              "    .card:hover {\n",
              "        transform: rotateY(180deg);\n",
              "    }\n",
              "\n",
              "    .card-face {\n",
              "        position: absolute;\n",
              "        width: 100%;\n",
              "        height: 100%;\n",
              "        backface-visibility: hidden;\n",
              "        border-radius: 10px;\n",
              "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
              "        padding: 20px;\n",
              "        box-sizing: border-box;\n",
              "        display: flex;\n",
              "        flex-direction: column;\n",
              "        justify-content: space-around;\n",
              "        align-items: center;\n",
              "        text-align: center;\n",
              "    }\n",
              "\n",
              "    .card-front {\n",
              "        background-color: #f0f0f0;\n",
              "        color: #333;\n",
              "    }\n",
              "\n",
              "    .card-back {\n",
              "        background-color: #333;\n",
              "        color: #f0f0f0;\n",
              "        transform: rotateY(180deg);\n",
              "        overflow-y: auto; /* Add scroll for long content */\n",
              "        text-align: left;\n",
              "        padding: 20px;\n",
              "    }\n",
              "\n",
              "    .card-back::-webkit-scrollbar {\n",
              "        width: 8px;\n",
              "    }\n",
              "\n",
              "    .card-back::-webkit-scrollbar-track {\n",
              "        background: #555;\n",
              "        border-radius: 10px;\n",
              "    }\n",
              "\n",
              "    .card-back::-webkit-scrollbar-thumb {\n",
              "        background: #888;\n",
              "        border-radius: 10px;\n",
              "    }\n",
              "\n",
              "    .card-back::-webkit-scrollbar-thumb:hover {\n",
              "        background: #bbb;\n",
              "    }\n",
              "\n",
              "\n",
              "    .card-title {\n",
              "        font-size: 24px;\n",
              "        font-weight: bold;\n",
              "        margin-bottom: 10px;\n",
              "    }\n",
              "\n",
              "     .card-section-title {\n",
              "        font-size: 16px;\n",
              "        font-weight: bold;\n",
              "        margin-top: 10px;\n",
              "        margin-bottom: 5px;\n",
              "        border-bottom: 1px solid #f0f0f0;\n",
              "        padding-bottom: 2px;\n",
              "    }\n",
              "\n",
              "    .card-text {\n",
              "        font-size: 14px;\n",
              "        margin-bottom: 5px;\n",
              "    }\n",
              "     .card-list-item {\n",
              "         font-size: 14px;\n",
              "         margin-bottom: 5px;\n",
              "         list-style-type: disc;\n",
              "         margin-left: 20px;\n",
              "         text-align: left;\n",
              "     }\n",
              "    </style>\n",
              "    <div class=\"card-container\">\n",
              "        <div class=\"card\">\n",
              "            <div class=\"card-face card-front\">\n",
              "                <div class=\"card-title\">Missy Frank</div>\n",
              "                 <!-- You can add an image or a brief summary on the front -->\n",
              "                 <img src=\"https://via.placeholder.com/150\" alt=\"Profile Image\" style=\"border-radius: 50%; margin-bottom: 10px;\">\n",
              "                <div class=\"card-text\">Hover to see details</div>\n",
              "            </div>\n",
              "            <div class=\"card-face card-back\">\n",
              "                \n",
              "    <div class=\"card-section-title\">Contact</div>\n",
              "    <div class=\"card-text\">Email: MissyFrank@email.com</div>\n",
              "    <div class=\"card-text\">Phone: (703) 555-3334</div>\n",
              "\n",
              "    <div class=\"card-section-title\">Education</div>\n",
              "    <div class=\"card-text\">Not Found</div>\n",
              "\n",
              "    <div class=\"card-section-title\">Experience Summary</div>\n",
              "    <div class=\"card-text\">• by training model to predict duplicate questions with 72% accuracy using natural language processing (NLP), advanced feature engineering.<br>• and sklearn machine learning (ML) pipelines.</div>\n",
              "\n",
              "    <div class=\"card-section-title\">Skills</div>\n",
              "    <div class=\"card-text\">Data Wrangling, Einstein, Informatica, Machine Learning, Predictive Modelling, Python, SQL, Sql Tableau, Tableau</div>\n",
              "\n",
              "    <div class=\"card-section-title\">Projects</div>\n",
              "    <div class=\"card-text\">• \" Used SQL and SOQL to cxtract, analysc, and interpret<br>• M data points: defincd<br>• key metrics and visualised data using Excel and Tableau dashboards<br>• \"Enhanced demand forecasting and streamlined data flow for<br>• + interfaces using<br>• Informatica Cloud, cleaning and correlating<br>• K+ customer data records with $<br>• in sales using python and sales analytics<br>• \" Created predictive models to prioritise campaigns and project customer lifetime<br>• value in collaboration with senior management</div>\n",
              "\n",
              "    <div class=\"card-section-title\">Certifications</div>\n",
              "    <div class=\"card-text\">Not Found</div>\n",
              "    \n",
              "            </div>\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmJ3cgpzDutcd4Np54EMzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}